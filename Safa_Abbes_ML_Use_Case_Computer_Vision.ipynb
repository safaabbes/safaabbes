{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/safaabbes/safaabbes/blob/main/Safa_Abbes_ML_Use_Case_Computer_Vision.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BuYM3mB2yQXZ"
      },
      "source": [
        "#ML Use Case: Computer Vision\n",
        "Task: Implement a proof of concept where you detect cars/trucks/motorcycles in images. \\\n",
        "Deadline: Monday 29 Mai 2023 \\\n",
        "Notes: For this task, you can use pre-trained models. No need to train your model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PTQfyCiOzEuw"
      },
      "source": [
        "#Description of the given problem:\n",
        "\n",
        "This is an object detection problem in computer vision which combines both classification and localization. We're dealing with multi-class classification involving 3 classes: Cars, Trucks and Motorcycles. Localization involve precise identification of the position of the object in the image. \\\n",
        "\n",
        "To accomplish this task, we'll need suitable datasets and models. No training will be done as we will use pre-trained models and we'll be mainly using the fiftyone toolkit and torchvision.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qjX1HDF6kZpH",
        "outputId": "6f3851e7-6bb0-4d7e-bb16-2b4870e4dff4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: fiftyone in /usr/local/lib/python3.10/dist-packages (0.20.1)\n",
            "Requirement already satisfied: aiofiles in /usr/local/lib/python3.10/dist-packages (from fiftyone) (23.1.0)\n",
            "Requirement already satisfied: argcomplete in /usr/local/lib/python3.10/dist-packages (from fiftyone) (3.0.8)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.10/dist-packages (from fiftyone) (1.26.141)\n",
            "Requirement already satisfied: cachetools in /usr/local/lib/python3.10/dist-packages (from fiftyone) (5.3.0)\n",
            "Requirement already satisfied: dacite<1.8.0,>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from fiftyone) (1.7.0)\n",
            "Requirement already satisfied: Deprecated in /usr/local/lib/python3.10/dist-packages (from fiftyone) (1.2.13)\n",
            "Requirement already satisfied: eventlet in /usr/local/lib/python3.10/dist-packages (from fiftyone) (0.33.3)\n",
            "Requirement already satisfied: ftfy in /usr/local/lib/python3.10/dist-packages (from fiftyone) (6.1.1)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.10/dist-packages (from fiftyone) (0.18.3)\n",
            "Requirement already satisfied: hypercorn>=0.13.2 in /usr/local/lib/python3.10/dist-packages (from fiftyone) (0.14.3)\n",
            "Requirement already satisfied: Jinja2>=3 in /usr/local/lib/python3.10/dist-packages (from fiftyone) (3.1.2)\n",
            "Requirement already satisfied: kaleido in /usr/local/lib/python3.10/dist-packages (from fiftyone) (0.2.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from fiftyone) (3.7.1)\n",
            "Requirement already satisfied: mongoengine==0.24.2 in /usr/local/lib/python3.10/dist-packages (from fiftyone) (0.24.2)\n",
            "Requirement already satisfied: motor>=2.5 in /usr/local/lib/python3.10/dist-packages (from fiftyone) (3.1.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from fiftyone) (1.22.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from fiftyone) (23.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from fiftyone) (1.5.3)\n",
            "Requirement already satisfied: Pillow>=6.2 in /usr/local/lib/python3.10/dist-packages (from fiftyone) (8.4.0)\n",
            "Requirement already satisfied: plotly>=4.14 in /usr/local/lib/python3.10/dist-packages (from fiftyone) (5.13.1)\n",
            "Requirement already satisfied: pprintpp in /usr/local/lib/python3.10/dist-packages (from fiftyone) (0.4.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from fiftyone) (5.9.5)\n",
            "Requirement already satisfied: pymongo>=3.12 in /usr/local/lib/python3.10/dist-packages (from fiftyone) (4.3.3)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.10/dist-packages (from fiftyone) (2022.7.1)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from fiftyone) (6.0)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from fiftyone) (2022.10.31)\n",
            "Requirement already satisfied: retrying in /usr/local/lib/python3.10/dist-packages (from fiftyone) (1.3.4)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from fiftyone) (1.2.2)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.10/dist-packages (from fiftyone) (0.19.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from fiftyone) (67.7.2)\n",
            "Requirement already satisfied: sseclient-py<2,>=1.7.2 in /usr/local/lib/python3.10/dist-packages (from fiftyone) (1.7.2)\n",
            "Requirement already satisfied: sse-starlette<1,>=0.10.3 in /usr/local/lib/python3.10/dist-packages (from fiftyone) (0.10.3)\n",
            "Requirement already satisfied: starlette==0.20.4 in /usr/local/lib/python3.10/dist-packages (from fiftyone) (0.20.4)\n",
            "Requirement already satisfied: strawberry-graphql==0.138.1 in /usr/local/lib/python3.10/dist-packages (from fiftyone) (0.138.1)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.10/dist-packages (from fiftyone) (0.8.10)\n",
            "Requirement already satisfied: xmltodict in /usr/local/lib/python3.10/dist-packages (from fiftyone) (0.13.0)\n",
            "Requirement already satisfied: universal-analytics-python3<2,>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from fiftyone) (1.1.1)\n",
            "Requirement already satisfied: fiftyone-brain<0.12,>=0.11 in /usr/local/lib/python3.10/dist-packages (from fiftyone) (0.11.0)\n",
            "Requirement already satisfied: fiftyone-db<0.5,>=0.4 in /usr/local/lib/python3.10/dist-packages (from fiftyone) (0.4.0)\n",
            "Requirement already satisfied: voxel51-eta<0.10,>=0.9 in /usr/local/lib/python3.10/dist-packages (from fiftyone) (0.9.0)\n",
            "Requirement already satisfied: opencv-python-headless in /usr/local/lib/python3.10/dist-packages (from fiftyone) (4.7.0.72)\n",
            "Requirement already satisfied: anyio<5,>=3.4.0 in /usr/local/lib/python3.10/dist-packages (from starlette==0.20.4->fiftyone) (3.6.2)\n",
            "Requirement already satisfied: graphql-core<3.3.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from strawberry-graphql==0.138.1->fiftyone) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.7.0 in /usr/local/lib/python3.10/dist-packages (from strawberry-graphql==0.138.1->fiftyone) (2.8.2)\n",
            "Requirement already satisfied: typing_extensions<5.0.0,>=3.7.4 in /usr/local/lib/python3.10/dist-packages (from strawberry-graphql==0.138.1->fiftyone) (4.5.0)\n",
            "Requirement already satisfied: scipy>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from fiftyone-brain<0.12,>=0.11->fiftyone) (1.10.1)\n",
            "Requirement already satisfied: h11 in /usr/local/lib/python3.10/dist-packages (from hypercorn>=0.13.2->fiftyone) (0.14.0)\n",
            "Requirement already satisfied: h2>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from hypercorn>=0.13.2->fiftyone) (4.1.0)\n",
            "Requirement already satisfied: priority in /usr/local/lib/python3.10/dist-packages (from hypercorn>=0.13.2->fiftyone) (2.0.0)\n",
            "Requirement already satisfied: toml in /usr/local/lib/python3.10/dist-packages (from hypercorn>=0.13.2->fiftyone) (0.10.2)\n",
            "Requirement already satisfied: wsproto>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from hypercorn>=0.13.2->fiftyone) (1.2.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from Jinja2>=3->fiftyone) (2.1.2)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from plotly>=4.14->fiftyone) (8.2.2)\n",
            "Requirement already satisfied: dnspython<3.0.0,>=1.16.0 in /usr/local/lib/python3.10/dist-packages (from pymongo>=3.12->fiftyone) (2.3.0)\n",
            "Requirement already satisfied: httpx>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from universal-analytics-python3<2,>=1.0.1->fiftyone) (0.24.1)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.10/dist-packages (from voxel51-eta<0.10,>=0.9->fiftyone) (0.3.6)\n",
            "Requirement already satisfied: glob2 in /usr/local/lib/python3.10/dist-packages (from voxel51-eta<0.10,>=0.9->fiftyone) (0.7)\n",
            "Requirement already satisfied: jsonlines in /usr/local/lib/python3.10/dist-packages (from voxel51-eta<0.10,>=0.9->fiftyone) (3.1.0)\n",
            "Requirement already satisfied: py7zr in /usr/local/lib/python3.10/dist-packages (from voxel51-eta<0.10,>=0.9->fiftyone) (0.20.5)\n",
            "Requirement already satisfied: rarfile in /usr/local/lib/python3.10/dist-packages (from voxel51-eta<0.10,>=0.9->fiftyone) (4.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from voxel51-eta<0.10,>=0.9->fiftyone) (2.27.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from voxel51-eta<0.10,>=0.9->fiftyone) (1.16.0)\n",
            "Requirement already satisfied: sortedcontainers in /usr/local/lib/python3.10/dist-packages (from voxel51-eta<0.10,>=0.9->fiftyone) (2.4.0)\n",
            "Requirement already satisfied: tzlocal in /usr/local/lib/python3.10/dist-packages (from voxel51-eta<0.10,>=0.9->fiftyone) (4.3)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.10/dist-packages (from voxel51-eta<0.10,>=0.9->fiftyone) (1.26.15)\n",
            "Requirement already satisfied: botocore<1.30.0,>=1.29.141 in /usr/local/lib/python3.10/dist-packages (from boto3->fiftyone) (1.29.141)\n",
            "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from boto3->fiftyone) (1.0.1)\n",
            "Requirement already satisfied: s3transfer<0.7.0,>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from boto3->fiftyone) (0.6.1)\n",
            "Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.10/dist-packages (from Deprecated->fiftyone) (1.14.1)\n",
            "Requirement already satisfied: greenlet>=0.3 in /usr/local/lib/python3.10/dist-packages (from eventlet->fiftyone) (2.0.2)\n",
            "Requirement already satisfied: wcwidth>=0.2.5 in /usr/local/lib/python3.10/dist-packages (from ftfy->fiftyone) (0.2.6)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->fiftyone) (1.0.7)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->fiftyone) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->fiftyone) (4.39.3)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->fiftyone) (1.4.4)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->fiftyone) (3.0.9)\n",
            "Requirement already satisfied: networkx>=2.2 in /usr/local/lib/python3.10/dist-packages (from scikit-image->fiftyone) (3.1)\n",
            "Requirement already satisfied: imageio>=2.4.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image->fiftyone) (2.25.1)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.10/dist-packages (from scikit-image->fiftyone) (2023.4.12)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image->fiftyone) (1.4.1)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->fiftyone) (1.2.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->fiftyone) (3.1.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.4.0->starlette==0.20.4->fiftyone) (3.4)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.4.0->starlette==0.20.4->fiftyone) (1.3.0)\n",
            "Requirement already satisfied: hyperframe<7,>=6.0 in /usr/local/lib/python3.10/dist-packages (from h2>=3.1.0->hypercorn>=0.13.2->fiftyone) (6.0.1)\n",
            "Requirement already satisfied: hpack<5,>=4.0 in /usr/local/lib/python3.10/dist-packages (from h2>=3.1.0->hypercorn>=0.13.2->fiftyone) (4.0.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx>=0.10.0->universal-analytics-python3<2,>=1.0.1->fiftyone) (2022.12.7)\n",
            "Requirement already satisfied: httpcore<0.18.0,>=0.15.0 in /usr/local/lib/python3.10/dist-packages (from httpx>=0.10.0->universal-analytics-python3<2,>=1.0.1->fiftyone) (0.17.2)\n",
            "Requirement already satisfied: attrs>=19.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonlines->voxel51-eta<0.10,>=0.9->fiftyone) (23.1.0)\n",
            "Requirement already satisfied: texttable in /usr/local/lib/python3.10/dist-packages (from py7zr->voxel51-eta<0.10,>=0.9->fiftyone) (1.6.7)\n",
            "Requirement already satisfied: pycryptodomex>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from py7zr->voxel51-eta<0.10,>=0.9->fiftyone) (3.18.0)\n",
            "Requirement already satisfied: pyzstd>=0.14.4 in /usr/local/lib/python3.10/dist-packages (from py7zr->voxel51-eta<0.10,>=0.9->fiftyone) (0.15.7)\n",
            "Requirement already satisfied: pyppmd<1.1.0,>=0.18.1 in /usr/local/lib/python3.10/dist-packages (from py7zr->voxel51-eta<0.10,>=0.9->fiftyone) (1.0.0)\n",
            "Requirement already satisfied: pybcj>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from py7zr->voxel51-eta<0.10,>=0.9->fiftyone) (1.0.1)\n",
            "Requirement already satisfied: multivolumefile>=0.2.3 in /usr/local/lib/python3.10/dist-packages (from py7zr->voxel51-eta<0.10,>=0.9->fiftyone) (0.2.3)\n",
            "Requirement already satisfied: brotli>=1.0.9 in /usr/local/lib/python3.10/dist-packages (from py7zr->voxel51-eta<0.10,>=0.9->fiftyone) (1.0.9)\n",
            "Requirement already satisfied: inflate64>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from py7zr->voxel51-eta<0.10,>=0.9->fiftyone) (0.3.1)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->voxel51-eta<0.10,>=0.9->fiftyone) (2.0.12)\n",
            "Requirement already satisfied: pytz-deprecation-shim in /usr/local/lib/python3.10/dist-packages (from tzlocal->voxel51-eta<0.10,>=0.9->fiftyone) (0.1.0.post0)\n",
            "Requirement already satisfied: tzdata in /usr/local/lib/python3.10/dist-packages (from pytz-deprecation-shim->tzlocal->voxel51-eta<0.10,>=0.9->fiftyone) (2023.3)\n"
          ]
        }
      ],
      "source": [
        "!pip install fiftyone"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "bTlkzM2ekbRo"
      },
      "outputs": [],
      "source": [
        "import fiftyone as fo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z6Ktsx9ehp-E"
      },
      "source": [
        "#Dataset\n",
        "\n",
        "Since we have the freedom of choice of the dataset, we'll explore the datasets available in the Dataset Zoo of fiftyone that are made for image detection purposes. These datasets include:\n",
        "\n",
        "*   COCO-2014\n",
        "*   COCO-2017\n",
        "*   KITTI\n",
        "*   KITTI Multiview\n",
        "*   Open Images V6\n",
        "*   Open Images V7\n",
        "*   VOC-2007\n",
        "*   VOC-2012\n",
        "\n",
        "After inspecting those datasets, I personally choose COCO-2017 as I find it the most suitable for this task.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "nXeG-XXlklaY"
      },
      "outputs": [],
      "source": [
        "import fiftyone.zoo as foz"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WqaMVs0nja3W"
      },
      "source": [
        "## COCO-2017 Dataset Details:\n",
        "\n",
        "COCO is a large-scale object detection, segmentation, and captioning dataset.\n",
        "This version contains images, bounding boxes, and segmentations for the 2017 version of the dataset.\n",
        "\n",
        "*  COCO defines 91 classes but the data only uses 80 classes.\n",
        "*  Some images from the train and validation sets donâ€™t have annotations.\n",
        "*  The test set does not have annotations."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_KSqr4sghrXZ",
        "outputId": "2e8b2406-4b98-4b00-faa4-c76e61f70e41"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading split 'validation' to '/root/fiftyone/coco-2017/validation' if necessary\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:fiftyone.zoo.datasets:Downloading split 'validation' to '/root/fiftyone/coco-2017/validation' if necessary\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found annotations at '/root/fiftyone/coco-2017/raw/instances_val2017.json'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:fiftyone.utils.coco:Found annotations at '/root/fiftyone/coco-2017/raw/instances_val2017.json'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sufficient images already downloaded\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:fiftyone.utils.coco:Sufficient images already downloaded\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Existing download of split 'validation' is sufficient\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:fiftyone.zoo.datasets:Existing download of split 'validation' is sufficient\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading existing dataset 'coco-2017-validation'. To reload from disk, either delete the existing dataset or provide a custom `dataset_name` to use\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:fiftyone.zoo.datasets:Loading existing dataset 'coco-2017-validation'. To reload from disk, either delete the existing dataset or provide a custom `dataset_name` to use\n"
          ]
        }
      ],
      "source": [
        "dataset = foz.load_zoo_dataset(\n",
        "    \"coco-2017\",\n",
        "    split=\"validation\",   #train, test or validation, we could use the train or validation but since the test has no annotations it might not help in the evaluation.\n",
        "    label_types=[\"detections\"], #detections or segmentations\n",
        "    classes=[\"car\",\"truck\",\"motorcycle\"], #We select only the specified objects to detect, only samples containing at least one instance of a specified class will be loaded\n",
        "    only_matching=True, #only load labels that match the classes or attrs requirements provided\n",
        "    # max_samples=100, #we use only 100 to make loading faster\n",
        "    shuffle=True,\n",
        "    seed=1234 #used when shuffle is True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Yjqm3OTm_Mn",
        "outputId": "fb1a8769-f40e-4bce-8f73-138c6c18f3fe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name:        coco-2017-validation\n",
            "Media type:  image\n",
            "Num samples: 725\n",
            "Persistent:  False\n",
            "Tags:        []\n",
            "Sample fields:\n",
            "    id:           fiftyone.core.fields.ObjectIdField\n",
            "    filepath:     fiftyone.core.fields.StringField\n",
            "    tags:         fiftyone.core.fields.ListField(fiftyone.core.fields.StringField)\n",
            "    metadata:     fiftyone.core.fields.EmbeddedDocumentField(fiftyone.core.metadata.ImageMetadata)\n",
            "    ground_truth: fiftyone.core.fields.EmbeddedDocumentField(fiftyone.core.labels.Detections)\n",
            "    faster_rcnn:  fiftyone.core.fields.EmbeddedDocumentField(fiftyone.core.labels.Detections)\n",
            "    eval_tp:      fiftyone.core.fields.IntField\n",
            "    eval_fp:      fiftyone.core.fields.IntField\n",
            "    eval_fn:      fiftyone.core.fields.IntField\n"
          ]
        }
      ],
      "source": [
        "# Print some information about the dataset\n",
        "print(dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2_xWWpIPn_Ri",
        "outputId": "2413af77-a7c6-48eb-c37c-324d1dca00f1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<Detection: {\n",
            "    'id': '6470825fa61f8abe35b5930e',\n",
            "    'attributes': {},\n",
            "    'tags': [],\n",
            "    'label': 'car',\n",
            "    'bounding_box': [\n",
            "        0.169625,\n",
            "        0.26844594594594595,\n",
            "        0.0410625,\n",
            "        0.05677927927927928,\n",
            "    ],\n",
            "    'mask': None,\n",
            "    'confidence': None,\n",
            "    'index': None,\n",
            "    'supercategory': 'vehicle',\n",
            "    'iscrowd': 0,\n",
            "    'eval': 'tp',\n",
            "    'eval_id': '647083cfa61f8abe35b5c9b1',\n",
            "    'eval_iou': 0.6889941412651497,\n",
            "}>\n"
          ]
        }
      ],
      "source": [
        "# Print a ground truth detection\n",
        "sample = dataset.first()\n",
        "print(sample.ground_truth.detections[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "Gl8V5-CSoEn3",
        "outputId": "2b41b49f-1042-41c7-f1f9-dd20b48b401a"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<style>\n",
              "\n",
              "@import url(\"https://fonts.googleapis.com/css2?family=Palanquin&display=swap\");\n",
              "\n",
              "body, html {\n",
              "  margin: 0;\n",
              "  padding: 0;\n",
              "  width: 100%;\n",
              "}\n",
              "\n",
              "#focontainer-58d58f8c-87f4-48fe-83f1-7b414052545c {\n",
              "  position: relative;\n",
              "  height: px;\n",
              "  display: block !important;\n",
              "}\n",
              "#foactivate-58d58f8c-87f4-48fe-83f1-7b414052545c {\n",
              "  font-weight: bold;\n",
              "  cursor: pointer;\n",
              "  font-size: 24px;\n",
              "  border-radius: 3px;\n",
              "  text-align: center;\n",
              "  padding: 0.5em;\n",
              "  color: rgb(255, 255, 255);\n",
              "  font-family: \"Palanquin\", sans-serif;\n",
              "  position: absolute;\n",
              "  left: 50%;\n",
              "  top: 50%;\n",
              "  width: 160px;\n",
              "  margin-left: -80px;\n",
              "  margin-top: -23px;\n",
              "  background: hsla(210,11%,15%, 0.8);\n",
              "  border: none;\n",
              "}\n",
              "#foactivate-58d58f8c-87f4-48fe-83f1-7b414052545c:focus {\n",
              "  outline: none;\n",
              "}\n",
              "#fooverlay-58d58f8c-87f4-48fe-83f1-7b414052545c {\n",
              "  width: 100%;\n",
              "  height: 100%;\n",
              "  background: hsla(208, 7%, 46%, 0.7);\n",
              "  position: absolute;\n",
              "  top: 0;\n",
              "  left: 0;\n",
              "  display: none;\n",
              "  cursor: pointer;\n",
              "}\n",
              "</style>\n",
              "<div id=\"focontainer-58d58f8c-87f4-48fe-83f1-7b414052545c\" style=\"display: none;\">\n",
              "   <div id=\"fooverlay-58d58f8c-87f4-48fe-83f1-7b414052545c\">\n",
              "      <button id=\"foactivate-58d58f8c-87f4-48fe-83f1-7b414052545c\" >Activate</button>\n",
              "   </div>\n",
              "</div>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "session = fo.launch_app(dataset)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KZril-Xtp-g0"
      },
      "source": [
        "#Model Selection\n",
        "Pytorch provides popular object detection models that are pre-trained including:\n",
        "\n",
        "*   Faster R-CNN\n",
        "*   FCOS\n",
        "*   RetinaNet\n",
        "*   SSD\n",
        "*   SSDlite\n",
        "\n",
        "I personally choose to work with Faster R-CNN that is pre-trained on the COCO dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "ALgvRqshp_sr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "21e3ad71-79ac-43a0-8cf1-979851f00f87"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.0.1+cu118)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.15.2+cu118)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.12.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch) (16.0.5)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.22.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchvision) (2.27.1)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (8.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.2)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (3.4)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install torch torchvision"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Torchvision's Faster R-CNN combines a ResNet-50 backbone network with a Feature Pyramid Network (FPN) to detect objects in images. The ResNet-50 backbone is responsible for extracting features from the input image at different scales, while the FPN helps to generate a set of feature maps with varying resolutions to handle objects of different sizes. The model then applies region proposal network (RPN) to generate potential object bounding box proposals and performs classification and bounding box regression on these proposals. "
      ],
      "metadata": {
        "id": "xDYVRYlKMfKp"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "TD7o442Tq-Vj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "11b7e612-3372-4315-cb71-dc13150dbe8f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning:\n",
            "\n",
            "The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning:\n",
            "\n",
            "Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=FasterRCNN_ResNet50_FPN_Weights.COCO_V1`. You can also use `weights=FasterRCNN_ResNet50_FPN_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "FasterRCNN(\n",
              "  (transform): GeneralizedRCNNTransform(\n",
              "      Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
              "      Resize(min_size=(800,), max_size=1333, mode='bilinear')\n",
              "  )\n",
              "  (backbone): BackboneWithFPN(\n",
              "    (body): IntermediateLayerGetter(\n",
              "      (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
              "      (bn1): FrozenBatchNorm2d(64, eps=0.0)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
              "      (layer1): Sequential(\n",
              "        (0): Bottleneck(\n",
              "          (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): FrozenBatchNorm2d(64, eps=0.0)\n",
              "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): FrozenBatchNorm2d(64, eps=0.0)\n",
              "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): FrozenBatchNorm2d(256, eps=0.0)\n",
              "          (relu): ReLU(inplace=True)\n",
              "          (downsample): Sequential(\n",
              "            (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): FrozenBatchNorm2d(256, eps=0.0)\n",
              "          )\n",
              "        )\n",
              "        (1): Bottleneck(\n",
              "          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): FrozenBatchNorm2d(64, eps=0.0)\n",
              "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): FrozenBatchNorm2d(64, eps=0.0)\n",
              "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): FrozenBatchNorm2d(256, eps=0.0)\n",
              "          (relu): ReLU(inplace=True)\n",
              "        )\n",
              "        (2): Bottleneck(\n",
              "          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): FrozenBatchNorm2d(64, eps=0.0)\n",
              "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): FrozenBatchNorm2d(64, eps=0.0)\n",
              "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): FrozenBatchNorm2d(256, eps=0.0)\n",
              "          (relu): ReLU(inplace=True)\n",
              "        )\n",
              "      )\n",
              "      (layer2): Sequential(\n",
              "        (0): Bottleneck(\n",
              "          (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): FrozenBatchNorm2d(128, eps=0.0)\n",
              "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "          (bn2): FrozenBatchNorm2d(128, eps=0.0)\n",
              "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): FrozenBatchNorm2d(512, eps=0.0)\n",
              "          (relu): ReLU(inplace=True)\n",
              "          (downsample): Sequential(\n",
              "            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "            (1): FrozenBatchNorm2d(512, eps=0.0)\n",
              "          )\n",
              "        )\n",
              "        (1): Bottleneck(\n",
              "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): FrozenBatchNorm2d(128, eps=0.0)\n",
              "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): FrozenBatchNorm2d(128, eps=0.0)\n",
              "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): FrozenBatchNorm2d(512, eps=0.0)\n",
              "          (relu): ReLU(inplace=True)\n",
              "        )\n",
              "        (2): Bottleneck(\n",
              "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): FrozenBatchNorm2d(128, eps=0.0)\n",
              "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): FrozenBatchNorm2d(128, eps=0.0)\n",
              "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): FrozenBatchNorm2d(512, eps=0.0)\n",
              "          (relu): ReLU(inplace=True)\n",
              "        )\n",
              "        (3): Bottleneck(\n",
              "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): FrozenBatchNorm2d(128, eps=0.0)\n",
              "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): FrozenBatchNorm2d(128, eps=0.0)\n",
              "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): FrozenBatchNorm2d(512, eps=0.0)\n",
              "          (relu): ReLU(inplace=True)\n",
              "        )\n",
              "      )\n",
              "      (layer3): Sequential(\n",
              "        (0): Bottleneck(\n",
              "          (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n",
              "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n",
              "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n",
              "          (relu): ReLU(inplace=True)\n",
              "          (downsample): Sequential(\n",
              "            (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "            (1): FrozenBatchNorm2d(1024, eps=0.0)\n",
              "          )\n",
              "        )\n",
              "        (1): Bottleneck(\n",
              "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n",
              "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n",
              "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n",
              "          (relu): ReLU(inplace=True)\n",
              "        )\n",
              "        (2): Bottleneck(\n",
              "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n",
              "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n",
              "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n",
              "          (relu): ReLU(inplace=True)\n",
              "        )\n",
              "        (3): Bottleneck(\n",
              "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n",
              "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n",
              "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n",
              "          (relu): ReLU(inplace=True)\n",
              "        )\n",
              "        (4): Bottleneck(\n",
              "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n",
              "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n",
              "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n",
              "          (relu): ReLU(inplace=True)\n",
              "        )\n",
              "        (5): Bottleneck(\n",
              "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n",
              "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n",
              "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n",
              "          (relu): ReLU(inplace=True)\n",
              "        )\n",
              "      )\n",
              "      (layer4): Sequential(\n",
              "        (0): Bottleneck(\n",
              "          (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): FrozenBatchNorm2d(512, eps=0.0)\n",
              "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "          (bn2): FrozenBatchNorm2d(512, eps=0.0)\n",
              "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): FrozenBatchNorm2d(2048, eps=0.0)\n",
              "          (relu): ReLU(inplace=True)\n",
              "          (downsample): Sequential(\n",
              "            (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "            (1): FrozenBatchNorm2d(2048, eps=0.0)\n",
              "          )\n",
              "        )\n",
              "        (1): Bottleneck(\n",
              "          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): FrozenBatchNorm2d(512, eps=0.0)\n",
              "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): FrozenBatchNorm2d(512, eps=0.0)\n",
              "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): FrozenBatchNorm2d(2048, eps=0.0)\n",
              "          (relu): ReLU(inplace=True)\n",
              "        )\n",
              "        (2): Bottleneck(\n",
              "          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): FrozenBatchNorm2d(512, eps=0.0)\n",
              "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): FrozenBatchNorm2d(512, eps=0.0)\n",
              "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): FrozenBatchNorm2d(2048, eps=0.0)\n",
              "          (relu): ReLU(inplace=True)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (fpn): FeaturePyramidNetwork(\n",
              "      (inner_blocks): ModuleList(\n",
              "        (0): Conv2dNormActivation(\n",
              "          (0): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "        )\n",
              "        (1): Conv2dNormActivation(\n",
              "          (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "        )\n",
              "        (2): Conv2dNormActivation(\n",
              "          (0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "        )\n",
              "        (3): Conv2dNormActivation(\n",
              "          (0): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "        )\n",
              "      )\n",
              "      (layer_blocks): ModuleList(\n",
              "        (0-3): 4 x Conv2dNormActivation(\n",
              "          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        )\n",
              "      )\n",
              "      (extra_blocks): LastLevelMaxPool()\n",
              "    )\n",
              "  )\n",
              "  (rpn): RegionProposalNetwork(\n",
              "    (anchor_generator): AnchorGenerator()\n",
              "    (head): RPNHead(\n",
              "      (conv): Sequential(\n",
              "        (0): Conv2dNormActivation(\n",
              "          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "          (1): ReLU(inplace=True)\n",
              "        )\n",
              "      )\n",
              "      (cls_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (bbox_pred): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
              "    )\n",
              "  )\n",
              "  (roi_heads): RoIHeads(\n",
              "    (box_roi_pool): MultiScaleRoIAlign(featmap_names=['0', '1', '2', '3'], output_size=(7, 7), sampling_ratio=2)\n",
              "    (box_head): TwoMLPHead(\n",
              "      (fc6): Linear(in_features=12544, out_features=1024, bias=True)\n",
              "      (fc7): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "    )\n",
              "    (box_predictor): FastRCNNPredictor(\n",
              "      (cls_score): Linear(in_features=1024, out_features=91, bias=True)\n",
              "      (bbox_pred): Linear(in_features=1024, out_features=364, bias=True)\n",
              "    )\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "\n",
        "# Run the model on GPU if it is available\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Load a pre-trained Faster R-CNN model\n",
        "model = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=True)\n",
        "model.to(device)\n",
        "model.eval() "
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can break down our model into: \n",
        "\n",
        "1. **ResNet-50 Backbone**: The ResNet-50 backbone is the core component of the model. It is responsible for feature extraction from the input image. ResNet-50 is a deep convolutional neural network that consists of multiple residual blocks. These blocks enable the model to learn complex and hierarchical features from the image at different scales. The backbone network processes the image and generates a set of feature maps with varying resolutions.\n",
        "\n",
        "2. **Feature Pyramid Network (FPN)**: FPN is used to address the challenge of detecting objects at different scales. It takes the feature maps produced by the ResNet-50 backbone and constructs a feature pyramid with multiple levels. The FPN combines low-resolution, semantically strong features with high-resolution, semantically weak features to create a set of feature maps that capture rich information at different scales. This pyramid structure allows the model to handle objects of different sizes effectively.\n",
        "\n",
        "3. **Region Proposal Network (RPN)**: The RPN is responsible for generating potential object bounding box proposals. It operates on the feature maps produced by the FPN and applies a set of predefined anchor boxes (or anchors) to identify regions of interest. The RPN predicts the likelihood of each anchor being an object or background and refines their bounding box coordinates. The highly confident proposals are passed on for further processing.\n",
        "\n",
        "4. **RoI (Region of Interest) Pooling**: After the RPN generates the object proposals, the RoI pooling block is applied. This block extracts fixed-size feature maps from each proposed region of interest. These features are then fed into subsequent layers for classification and bounding box regression.\n",
        "\n",
        "5. **Classification and Bounding Box Regression Heads:** The final stages of the model consist of classification and bounding box regression heads. The classification head performs object classification, predicting the probability of each proposed region belonging to different object classes. The bounding box regression head refines the coordinates of the proposed bounding boxes, aiming to improve the localization accuracy of the detected objects."
      ],
      "metadata": {
        "id": "hiSmG7-TLhuY"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "upQ-qjh0r5Iw"
      },
      "source": [
        "#Add predictions to dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tf0KCy0usHxg",
        "outputId": "1bc8948b-db17-4bbf-bc11-1f2bd644d0cc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 100% |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 725/725 [2.0m elapsed, 0s remaining, 5.9 samples/s]      \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:eta.core.utils: 100% |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 725/725 [2.0m elapsed, 0s remaining, 5.9 samples/s]      \n"
          ]
        }
      ],
      "source": [
        "from PIL import Image\n",
        "from torchvision.transforms import functional as func\n",
        "import fiftyone as fo\n",
        "\n",
        "# Create a mapping between the desired classes and their assigned label in the default classes.\n",
        "all_classes = dataset.default_classes\n",
        "desired_classes = ['car', 'motorcycle', 'truck']\n",
        "mapping = {}\n",
        "for i, item in enumerate(all_classes):\n",
        "    if item in desired_classes:\n",
        "        mapping[i]=item\n",
        "\n",
        "# Add predictions to samples\n",
        "predictions_view = dataset.view()\n",
        "with fo.ProgressBar() as pb:\n",
        "    for sample in pb(predictions_view):\n",
        "        # Load image\n",
        "        image = Image.open(sample.filepath)\n",
        "        image = func.to_tensor(image).to(device)\n",
        "        c, h, w = image.shape\n",
        "        \n",
        "        # Perform inference\n",
        "        preds = model([image])[0]\n",
        "        filtered_preds = {}\n",
        "        filtered_preds['boxes'] = preds['boxes'][torch.tensor([label in list(mapping.keys()) for label in preds['labels']])]\n",
        "        filtered_preds['labels'] = preds['labels'][torch.tensor([label in list(mapping.keys()) for label in preds['labels']])]\n",
        "        filtered_preds['scores'] = preds['scores'][torch.tensor([label in list(mapping.keys()) for label in preds['labels']])]\n",
        "        labels = filtered_preds[\"labels\"].cpu().detach().numpy()\n",
        "        scores = filtered_preds[\"scores\"].cpu().detach().numpy()\n",
        "        boxes = filtered_preds[\"boxes\"].cpu().detach().numpy()\n",
        "\n",
        "        # Convert detections to FiftyOne format\n",
        "        detections = []\n",
        "        for label, score, box in zip(labels, scores, boxes):\n",
        "            # Convert to [top-left-x, top-left-y, width, height]\n",
        "            # in relative coordinates in [0, 1] x [0, 1]\n",
        "            x1, y1, x2, y2 = box\n",
        "            rel_box = [x1 / w, y1 / h, (x2 - x1) / w, (y2 - y1) / h]\n",
        "\n",
        "            detections.append(\n",
        "                fo.Detection(\n",
        "                    label=mapping[label],\n",
        "                    bounding_box=rel_box,\n",
        "                    confidence=score\n",
        "                )\n",
        "            )\n",
        "        \n",
        "        # Save predictions to dataset\n",
        "        sample[\"faster_rcnn\"] = fo.Detections(detections=detections)\n",
        "        sample.save()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 805
        },
        "id": "OkI4x-_ysa5x",
        "outputId": "358b95f8-b50f-4e85-e811-765ce305b343"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<style>\n",
              "\n",
              "@import url(\"https://fonts.googleapis.com/css2?family=Palanquin&display=swap\");\n",
              "\n",
              "body, html {\n",
              "  margin: 0;\n",
              "  padding: 0;\n",
              "  width: 100%;\n",
              "}\n",
              "\n",
              "#focontainer-00f2203b-5e51-42ed-9c80-66f3af61b6ac {\n",
              "  position: relative;\n",
              "  height: px;\n",
              "  display: block !important;\n",
              "}\n",
              "#foactivate-00f2203b-5e51-42ed-9c80-66f3af61b6ac {\n",
              "  font-weight: bold;\n",
              "  cursor: pointer;\n",
              "  font-size: 24px;\n",
              "  border-radius: 3px;\n",
              "  text-align: center;\n",
              "  padding: 0.5em;\n",
              "  color: rgb(255, 255, 255);\n",
              "  font-family: \"Palanquin\", sans-serif;\n",
              "  position: absolute;\n",
              "  left: 50%;\n",
              "  top: 50%;\n",
              "  width: 160px;\n",
              "  margin-left: -80px;\n",
              "  margin-top: -23px;\n",
              "  background: hsla(210,11%,15%, 0.8);\n",
              "  border: none;\n",
              "}\n",
              "#foactivate-00f2203b-5e51-42ed-9c80-66f3af61b6ac:focus {\n",
              "  outline: none;\n",
              "}\n",
              "#fooverlay-00f2203b-5e51-42ed-9c80-66f3af61b6ac {\n",
              "  width: 100%;\n",
              "  height: 100%;\n",
              "  background: hsla(208, 7%, 46%, 0.7);\n",
              "  position: absolute;\n",
              "  top: 0;\n",
              "  left: 0;\n",
              "  display: none;\n",
              "  cursor: pointer;\n",
              "}\n",
              "</style>\n",
              "<div id=\"focontainer-00f2203b-5e51-42ed-9c80-66f3af61b6ac\" style=\"display: none;\">\n",
              "   <div id=\"fooverlay-00f2203b-5e51-42ed-9c80-66f3af61b6ac\">\n",
              "      <button id=\"foactivate-00f2203b-5e51-42ed-9c80-66f3af61b6ac\" >Activate</button>\n",
              "   </div>\n",
              "</div>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "session.view = predictions_view"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "By looking at the samples, we can notice many detection errors or duplicates done by the model with a low score. To overcome this issue we can simply apply a threshold and leave out the detections the model is most confident about."
      ],
      "metadata": {
        "id": "i04zRFKQPzZC"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "0J5B0RST6ZxD"
      },
      "outputs": [],
      "source": [
        "from fiftyone import ViewField as F\n",
        "\n",
        "# Only contains detections with confidence above threshold\n",
        "threshold = 0.75\n",
        "high_conf_view = predictions_view.filter_labels(\"faster_rcnn\", F(\"confidence\") > threshold, only_matches=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NYmVjhVL60pX",
        "outputId": "9be35a14-1c38-4f84-92a9-e63194ce11b1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset:     coco-2017-validation\n",
            "Media type:  image\n",
            "Num samples: 725\n",
            "Sample fields:\n",
            "    id:           fiftyone.core.fields.ObjectIdField\n",
            "    filepath:     fiftyone.core.fields.StringField\n",
            "    tags:         fiftyone.core.fields.ListField(fiftyone.core.fields.StringField)\n",
            "    metadata:     fiftyone.core.fields.EmbeddedDocumentField(fiftyone.core.metadata.ImageMetadata)\n",
            "    ground_truth: fiftyone.core.fields.EmbeddedDocumentField(fiftyone.core.labels.Detections)\n",
            "    faster_rcnn:  fiftyone.core.fields.EmbeddedDocumentField(fiftyone.core.labels.Detections)\n",
            "    eval_tp:      fiftyone.core.fields.IntField\n",
            "    eval_fp:      fiftyone.core.fields.IntField\n",
            "    eval_fn:      fiftyone.core.fields.IntField\n",
            "View stages:\n",
            "    1. FilterLabels(field='faster_rcnn', filter={'$gt': ['$$this.confidence', 0.75]}, only_matches=False, trajectories=False)\n"
          ]
        }
      ],
      "source": [
        "# Print some information about the view\n",
        "print(high_conf_view)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I57IGTr065Cm",
        "outputId": "addeb7b8-2782-4a5c-e06b-334092cc614c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<Detection: {\n",
            "    'id': '64708c5ba61f8abe35b62bb8',\n",
            "    'attributes': {},\n",
            "    'tags': [],\n",
            "    'label': 'motorcycle',\n",
            "    'bounding_box': [\n",
            "        0.8074630737304688,\n",
            "        0.301586288589615,\n",
            "        0.19253692626953126,\n",
            "        0.26718273678341425,\n",
            "    ],\n",
            "    'mask': None,\n",
            "    'confidence': 0.9974988102912903,\n",
            "    'index': None,\n",
            "}>\n"
          ]
        }
      ],
      "source": [
        "# Print a prediction from the view to verify that its confidence is > 0.75\n",
        "sample = high_conf_view.first()\n",
        "print(sample.faster_rcnn.detections[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 805
        },
        "id": "K-QSUDuC68vE",
        "outputId": "a1b63941-c258-4129-d8ac-ae5b04d56461"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<style>\n",
              "\n",
              "@import url(\"https://fonts.googleapis.com/css2?family=Palanquin&display=swap\");\n",
              "\n",
              "body, html {\n",
              "  margin: 0;\n",
              "  padding: 0;\n",
              "  width: 100%;\n",
              "}\n",
              "\n",
              "#focontainer-01680f3c-74d5-4442-a47c-ce0b009f2b22 {\n",
              "  position: relative;\n",
              "  height: px;\n",
              "  display: block !important;\n",
              "}\n",
              "#foactivate-01680f3c-74d5-4442-a47c-ce0b009f2b22 {\n",
              "  font-weight: bold;\n",
              "  cursor: pointer;\n",
              "  font-size: 24px;\n",
              "  border-radius: 3px;\n",
              "  text-align: center;\n",
              "  padding: 0.5em;\n",
              "  color: rgb(255, 255, 255);\n",
              "  font-family: \"Palanquin\", sans-serif;\n",
              "  position: absolute;\n",
              "  left: 50%;\n",
              "  top: 50%;\n",
              "  width: 160px;\n",
              "  margin-left: -80px;\n",
              "  margin-top: -23px;\n",
              "  background: hsla(210,11%,15%, 0.8);\n",
              "  border: none;\n",
              "}\n",
              "#foactivate-01680f3c-74d5-4442-a47c-ce0b009f2b22:focus {\n",
              "  outline: none;\n",
              "}\n",
              "#fooverlay-01680f3c-74d5-4442-a47c-ce0b009f2b22 {\n",
              "  width: 100%;\n",
              "  height: 100%;\n",
              "  background: hsla(208, 7%, 46%, 0.7);\n",
              "  position: absolute;\n",
              "  top: 0;\n",
              "  left: 0;\n",
              "  display: none;\n",
              "  cursor: pointer;\n",
              "}\n",
              "</style>\n",
              "<div id=\"focontainer-01680f3c-74d5-4442-a47c-ce0b009f2b22\" style=\"display: none;\">\n",
              "   <div id=\"fooverlay-01680f3c-74d5-4442-a47c-ce0b009f2b22\">\n",
              "      <button id=\"foactivate-01680f3c-74d5-4442-a47c-ce0b009f2b22\" >Activate</button>\n",
              "   </div>\n",
              "</div>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Load high confidence view in the App\n",
        "session.view = high_conf_view"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can clearly see that the detections are cleaner this way. Changing the threshold value leads to different results.There is a trade-off between precision and recall. A high threshold will result in fewer but more confident detections, while a lower threshold will yield more detections but with potentially lower confidence. If high precision is crucial, we may choose a higher threshold that provides a good balance between precision and recall. If maximizing recall is more important, we may opt for a lower threshold that captures more positive instances but with potential false positives.  For example, in certain scenarios where false positives are highly undesirable, we may opt for a higher threshold to be more conservative and reduce the chances of incorrect detections. In my opinion, if we were dealing with autonomous vehicules, incorrectly detecting objects that are not present can lead to unnecessary braking or evasive maneuvers, which can be dangerous or disruptive to traffic flow. Emphasizing precision helps reduce the likelihood of false positive detections and minimizes unnecessary interventions. Furthermore, autonomous cars typically have limited computational resources. Prioritizing precision helps reduce computational load by minimizing false positives. This enables efficient resource allocation, allowing the system to process a larger number of true positive detections effectively. However, A very high threshold that maximizes precision may lead to missed detections (lower recall) of certain objects, which could be problematic for safety. "
      ],
      "metadata": {
        "id": "UgWwJlJgQHvT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Detection Evaluation "
      ],
      "metadata": {
        "id": "ASm5gSa6Np0K"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The evaluate_detections function in FiftyOne is specifically designed to evaluate object detection results. It takes as input ground truth annotations and predicted detections, and then computes various evaluation metrics to assess the performance of the model. These metrics commonly include precision, recall, average precision (AP), and mean average precision (mAP)."
      ],
      "metadata": {
        "id": "AjFiG0M0S6Jx"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RdQ4bSsz8Q1R",
        "outputId": "211362c8-068e-4388-a400-9c35029e5798"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluating detections...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:fiftyone.utils.eval.detection:Evaluating detections...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 100% |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 725/725 [16.3s elapsed, 0s remaining, 43.8 samples/s]      \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:eta.core.utils: 100% |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 725/725 [16.3s elapsed, 0s remaining, 43.8 samples/s]      \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Performing IoU sweep...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:fiftyone.utils.eval.coco:Performing IoU sweep...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 100% |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 725/725 [10.2s elapsed, 0s remaining, 90.5 samples/s]      \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:eta.core.utils: 100% |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 725/725 [10.2s elapsed, 0s remaining, 90.5 samples/s]      \n"
          ]
        }
      ],
      "source": [
        "# Evaluate the predictions in the `faster_rcnn` field of our `high_conf_view`\n",
        "# with respect to the objects in the `ground_truth` field\n",
        "results = high_conf_view.evaluate_detections(\n",
        "    \"faster_rcnn\",\n",
        "    gt_field=\"ground_truth\",\n",
        "    eval_key=\"eval\",\n",
        "    compute_mAP=True,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "llc8tw9G8RSo",
        "outputId": "dcf62fda-53b3-46a4-aa33-06045c3b657e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         car       0.79      0.61      0.68      1986\n",
            "  motorcycle       0.82      0.62      0.71       372\n",
            "       truck       0.71      0.41      0.52       415\n",
            "\n",
            "   micro avg       0.78      0.58      0.67      2773\n",
            "   macro avg       0.77      0.55      0.64      2773\n",
            "weighted avg       0.78      0.58      0.66      2773\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Print a classification report \n",
        "results.print_report(classes=['car','motorcycle','truck'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lSBewfrx8b1K",
        "outputId": "5e74df6b-daf6-4322-8631-f17557cc6a9c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.30566323550504065\n"
          ]
        }
      ],
      "source": [
        "print(results.mAP())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "MJJJ-NoX872v",
        "outputId": "7b9774c9-44f5-4f0a-bfa2-791f10d687c7"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-2.18.2.min.js\"></script>                <div id=\"3ee19aa1-f675-4ce8-9a99-619a763a134d\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"3ee19aa1-f675-4ce8-9a99-619a763a134d\")) {                    Plotly.newPlot(                        \"3ee19aa1-f675-4ce8-9a99-619a763a134d\",                        [{\"customdata\":[0.9993991851806641,0.9979641139507294,0.9952123582363128,0.897389155626297,0.8967658221721649,0.8961357831954956,0.8954934358596802,0.8946597695350647,0.8940334379673004,0.8932699680328369,0.8918355941772461,0.8902830064296723,0.888801223039627,0.8868687331676484,0.8839103519916535,0.8786080956459046,0.869950932264328,0.7871115386486054,0.785680615901947,0.7841947138309479,0.7827133536338806,0.7808459281921387,0.7789211988449096,0.7768294394016266,0.7746202945709229,0.7712799191474915,0.768555223941803,0.7643544912338257,0.7589547097682953,0.7532195389270783,0.6701762199401855,0.6676225185394287,0.6642452836036682,0.6613627195358276,0.6575507819652557,0.6531598091125488,0.6484511971473694,0.6436528921127319,0.6375405728816986,0.6282257199287414,0.5481844902038574,0.5434163630008697,0.5382832169532776,0.5323486864566803,0.526470023393631,0.44272997975349426,0.43824260830879214,0.4328714609146118,0.42697367668151853,0.42069987058639524,0.3382376849651337,0.33323289155960084,0.3276108682155609,0.24723362922668457,0.24256954789161683,0.2380746841430664,0.15882392525672911,0.1551771342754364,0.07784826159477234,0.07579341530799866,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],\"hovertemplate\":\"<b>class: %{text}</b><br>recall: %{x:.3f}<br>precision: %{y:.3f}<br>threshold: %{customdata:.3f}<extra></extra>\",\"line\":{\"color\":\"#3366CC\"},\"mode\":\"lines\",\"name\":\"car (AP = 0.350)\",\"text\":[\"car\",\"car\",\"car\",\"car\",\"car\",\"car\",\"car\",\"car\",\"car\",\"car\",\"car\",\"car\",\"car\",\"car\",\"car\",\"car\",\"car\",\"car\",\"car\",\"car\",\"car\",\"car\",\"car\",\"car\",\"car\",\"car\",\"car\",\"car\",\"car\",\"car\",\"car\",\"car\",\"car\",\"car\",\"car\",\"car\",\"car\",\"car\",\"car\",\"car\",\"car\",\"car\",\"car\",\"car\",\"car\",\"car\",\"car\",\"car\",\"car\",\"car\",\"car\",\"car\",\"car\",\"car\",\"car\",\"car\",\"car\",\"car\",\"car\",\"car\",\"car\",\"car\",\"car\",\"car\",\"car\",\"car\",\"car\",\"car\",\"car\",\"car\",\"car\",\"car\",\"car\",\"car\",\"car\",\"car\",\"car\",\"car\",\"car\",\"car\",\"car\",\"car\",\"car\",\"car\",\"car\",\"car\",\"car\",\"car\",\"car\",\"car\",\"car\",\"car\",\"car\",\"car\",\"car\",\"car\",\"car\",\"car\",\"car\",\"car\",\"car\"],\"x\":[0.0,0.01,0.02,0.03,0.04,0.05,0.06,0.07,0.08,0.09,0.1,0.11,0.12,0.13,0.14,0.15,0.16,0.17,0.18,0.19,0.2,0.21,0.22,0.23,0.24,0.25,0.26,0.27,0.28,0.29,0.3,0.31,0.32,0.33,0.34,0.35000000000000003,0.36,0.37,0.38,0.39,0.4,0.41000000000000003,0.42,0.43,0.44,0.45,0.46,0.47000000000000003,0.48,0.49,0.5,0.51,0.52,0.53,0.54,0.55,0.56,0.5700000000000001,0.58,0.59,0.6,0.61,0.62,0.63,0.64,0.65,0.66,0.67,0.68,0.6900000000000001,0.7000000000000001,0.71,0.72,0.73,0.74,0.75,0.76,0.77,0.78,0.79,0.8,0.81,0.8200000000000001,0.8300000000000001,0.84,0.85,0.86,0.87,0.88,0.89,0.9,0.91,0.92,0.93,0.9400000000000001,0.9500000000000001,0.96,0.97,0.98,0.99,1.0],\"y\":[1.0,0.8983709273182958,0.8839891818796485,0.8633797909407666,0.8425932774231445,0.8299476981552681,0.8198794826307697,0.8140958810577906,0.8124463892555809,0.80656196277588,0.7936144230740847,0.7752300937709058,0.771256635772028,0.7653183706745736,0.7593887107728435,0.7506659130532947,0.7426177745163909,0.7140562493242923,0.711173400572492,0.707439745401356,0.7051147436797017,0.7012293389617968,0.6972212635472398,0.6914226485470573,0.6874970878624216,0.681614366045739,0.6769013212170719,0.6694999884115075,0.6603621264889298,0.6544819347228422,0.6083799100126241,0.6047255112658931,0.5988337979719994,0.5941625771727722,0.5889962894414669,0.5821728081544848,0.5770610366667142,0.5723424571535015,0.5646852898990354,0.5563874387441012,0.49880184300710806,0.4928810628140393,0.4878986089311482,0.4827368618417302,0.47867193452082757,0.41236927598908746,0.40901902224527886,0.40439078196292,0.4001323260450412,0.3955937692443584,0.3242443337171926,0.3210868423067278,0.3162452296324496,0.24287878385259404,0.23903977321948272,0.23478677093361838,0.1588248756896669,0.15619128663104215,0.0795,0.07806896551724138,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],\"type\":\"scatter\"},{\"customdata\":[0.9995326995849609,0.9991703450679779,0.8990660727024078,0.8988653123378754,0.8983779013156891,0.8979487717151642,0.8973117768764496,0.8954517900943756,0.8934967815876007,0.8781314074993134,0.7970010101795196,0.7966036438941956,0.7961955070495605,0.7958760261535645,0.7954061686992645,0.7946900010108948,0.7940735936164856,0.7930367469787598,0.7918480932712555,0.790767902135849,0.7896657824516297,0.7866924285888672,0.7840168058872223,0.7743067741394043,0.6894216179847718,0.6887386023998261,0.6872637927532196,0.6851288914680481,0.6840339839458466,0.6814531803131103,0.679635512828827,0.6775573790073395,0.6743480920791626,0.6683809340000153,0.662078732252121,0.5760098576545716,0.5738836467266083,0.5717513084411621,0.5684009611606597,0.5640262365341187,0.5601101636886596,0.556275337934494,0.547774338722229,0.46373326778411866,0.45952161550521853,0.45526083111763,0.4504863440990448,0.443448007106781,0.43481387495994567,0.3551630795001984,0.34920516014099123,0.34378349781036377,0.261100709438324,0.2568087637424469,0.25248090028762815,0.24828317761421204,0.166287100315094,0.16454511284828185,0.16186864972114562,0.15827104449272156,0.0782501220703125,0.0773745596408844,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],\"hovertemplate\":\"<b>class: %{text}</b><br>recall: %{x:.3f}<br>precision: %{y:.3f}<br>threshold: %{customdata:.3f}<extra></extra>\",\"line\":{\"color\":\"#DC3912\"},\"mode\":\"lines\",\"name\":\"motorcycle (AP = 0.346)\",\"text\":[\"motorcycle\",\"motorcycle\",\"motorcycle\",\"motorcycle\",\"motorcycle\",\"motorcycle\",\"motorcycle\",\"motorcycle\",\"motorcycle\",\"motorcycle\",\"motorcycle\",\"motorcycle\",\"motorcycle\",\"motorcycle\",\"motorcycle\",\"motorcycle\",\"motorcycle\",\"motorcycle\",\"motorcycle\",\"motorcycle\",\"motorcycle\",\"motorcycle\",\"motorcycle\",\"motorcycle\",\"motorcycle\",\"motorcycle\",\"motorcycle\",\"motorcycle\",\"motorcycle\",\"motorcycle\",\"motorcycle\",\"motorcycle\",\"motorcycle\",\"motorcycle\",\"motorcycle\",\"motorcycle\",\"motorcycle\",\"motorcycle\",\"motorcycle\",\"motorcycle\",\"motorcycle\",\"motorcycle\",\"motorcycle\",\"motorcycle\",\"motorcycle\",\"motorcycle\",\"motorcycle\",\"motorcycle\",\"motorcycle\",\"motorcycle\",\"motorcycle\",\"motorcycle\",\"motorcycle\",\"motorcycle\",\"motorcycle\",\"motorcycle\",\"motorcycle\",\"motorcycle\",\"motorcycle\",\"motorcycle\",\"motorcycle\",\"motorcycle\",\"motorcycle\",\"motorcycle\",\"motorcycle\",\"motorcycle\",\"motorcycle\",\"motorcycle\",\"motorcycle\",\"motorcycle\",\"motorcycle\",\"motorcycle\",\"motorcycle\",\"motorcycle\",\"motorcycle\",\"motorcycle\",\"motorcycle\",\"motorcycle\",\"motorcycle\",\"motorcycle\",\"motorcycle\",\"motorcycle\",\"motorcycle\",\"motorcycle\",\"motorcycle\",\"motorcycle\",\"motorcycle\",\"motorcycle\",\"motorcycle\",\"motorcycle\",\"motorcycle\",\"motorcycle\",\"motorcycle\",\"motorcycle\",\"motorcycle\",\"motorcycle\",\"motorcycle\",\"motorcycle\",\"motorcycle\",\"motorcycle\",\"motorcycle\"],\"x\":[0.0,0.01,0.02,0.03,0.04,0.05,0.06,0.07,0.08,0.09,0.1,0.11,0.12,0.13,0.14,0.15,0.16,0.17,0.18,0.19,0.2,0.21,0.22,0.23,0.24,0.25,0.26,0.27,0.28,0.29,0.3,0.31,0.32,0.33,0.34,0.35000000000000003,0.36,0.37,0.38,0.39,0.4,0.41000000000000003,0.42,0.43,0.44,0.45,0.46,0.47000000000000003,0.48,0.49,0.5,0.51,0.52,0.53,0.54,0.55,0.56,0.5700000000000001,0.58,0.59,0.6,0.61,0.62,0.63,0.64,0.65,0.66,0.67,0.68,0.6900000000000001,0.7000000000000001,0.71,0.72,0.73,0.74,0.75,0.76,0.77,0.78,0.79,0.8,0.81,0.8200000000000001,0.8300000000000001,0.84,0.85,0.86,0.87,0.88,0.89,0.9,0.91,0.92,0.93,0.9400000000000001,0.9500000000000001,0.96,0.97,0.98,0.99,1.0],\"y\":[0.9133333333333333,0.8704761904761904,0.8229584931197834,0.8203943905556809,0.8085664335664335,0.8075407925407925,0.7997681331014664,0.7924668213730713,0.7909809145103263,0.7750869715080241,0.7607503607503607,0.7598135926004779,0.7511434676434676,0.7476661230702326,0.7430942261543355,0.7382081658705609,0.7366268881982017,0.7278847362568293,0.7206221531609128,0.7171187343277875,0.7155952723201555,0.7075799066087497,0.7048180786942976,0.6940579482351693,0.6542549649162479,0.6514164695730236,0.6486569953537573,0.6410403709331014,0.6356650884881251,0.6255201942437755,0.6216768571406754,0.6173867365004948,0.6079688415527914,0.6023940992695915,0.593325440442937,0.5336054735234529,0.5317459128516978,0.5265694483882702,0.5231953640940816,0.515201355944266,0.5121378741028362,0.5078482950083083,0.5005394594509849,0.43589537898252956,0.4327532066988553,0.42894744299479226,0.42549429252268434,0.4192880482327458,0.414156696972641,0.34585055616699234,0.3417205645160427,0.337484719244397,0.2632095780646258,0.25972685275497,0.2543339826804394,0.25138013842924933,0.17119371101426983,0.16918421689663518,0.16763736263736262,0.16573577425373134,0.08371212121212121,0.08327137546468402,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],\"type\":\"scatter\"},{\"customdata\":[0.9985981583595276,0.9921746969223022,0.9743224203586578,0.8925821721553803,0.8908150434494019,0.8880688965320587,0.8856228590011597,0.8826949656009674,0.8774500608444213,0.8701633751392365,0.8641421079635621,0.8588984370231628,0.8528405427932739,0.772724586725235,0.769450169801712,0.7631805598735809,0.7582992196083069,0.7525028169155121,0.7466398239135742,0.7420603811740876,0.7349366247653961,0.7256431639194488,0.6394203186035157,0.6325850367546082,0.6284241676330566,0.6222751379013062,0.6146186113357544,0.6068204939365387,0.5221352696418762,0.514758038520813,0.5074751913547516,0.4240363299846649,0.4193688631057739,0.4155998885631561,0.33519611954689027,0.331463885307312,0.32444576025009153,0.24151042699813843,0.23699957728385926,0.15693360567092896,0.07810314297676087,0.07644072771072388,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],\"hovertemplate\":\"<b>class: %{text}</b><br>recall: %{x:.3f}<br>precision: %{y:.3f}<br>threshold: %{customdata:.3f}<extra></extra>\",\"line\":{\"color\":\"#FF9900\"},\"mode\":\"lines\",\"name\":\"truck (AP = 0.221)\",\"text\":[\"truck\",\"truck\",\"truck\",\"truck\",\"truck\",\"truck\",\"truck\",\"truck\",\"truck\",\"truck\",\"truck\",\"truck\",\"truck\",\"truck\",\"truck\",\"truck\",\"truck\",\"truck\",\"truck\",\"truck\",\"truck\",\"truck\",\"truck\",\"truck\",\"truck\",\"truck\",\"truck\",\"truck\",\"truck\",\"truck\",\"truck\",\"truck\",\"truck\",\"truck\",\"truck\",\"truck\",\"truck\",\"truck\",\"truck\",\"truck\",\"truck\",\"truck\",\"truck\",\"truck\",\"truck\",\"truck\",\"truck\",\"truck\",\"truck\",\"truck\",\"truck\",\"truck\",\"truck\",\"truck\",\"truck\",\"truck\",\"truck\",\"truck\",\"truck\",\"truck\",\"truck\",\"truck\",\"truck\",\"truck\",\"truck\",\"truck\",\"truck\",\"truck\",\"truck\",\"truck\",\"truck\",\"truck\",\"truck\",\"truck\",\"truck\",\"truck\",\"truck\",\"truck\",\"truck\",\"truck\",\"truck\",\"truck\",\"truck\",\"truck\",\"truck\",\"truck\",\"truck\",\"truck\",\"truck\",\"truck\",\"truck\",\"truck\",\"truck\",\"truck\",\"truck\",\"truck\",\"truck\",\"truck\",\"truck\",\"truck\",\"truck\"],\"x\":[0.0,0.01,0.02,0.03,0.04,0.05,0.06,0.07,0.08,0.09,0.1,0.11,0.12,0.13,0.14,0.15,0.16,0.17,0.18,0.19,0.2,0.21,0.22,0.23,0.24,0.25,0.26,0.27,0.28,0.29,0.3,0.31,0.32,0.33,0.34,0.35000000000000003,0.36,0.37,0.38,0.39,0.4,0.41000000000000003,0.42,0.43,0.44,0.45,0.46,0.47000000000000003,0.48,0.49,0.5,0.51,0.52,0.53,0.54,0.55,0.56,0.5700000000000001,0.58,0.59,0.6,0.61,0.62,0.63,0.64,0.65,0.66,0.67,0.68,0.6900000000000001,0.7000000000000001,0.71,0.72,0.73,0.74,0.75,0.76,0.77,0.78,0.79,0.8,0.81,0.8200000000000001,0.8300000000000001,0.84,0.85,0.86,0.87,0.88,0.89,0.9,0.91,0.92,0.93,0.9400000000000001,0.9500000000000001,0.96,0.97,0.98,0.99,1.0],\"y\":[0.9072164948453608,0.8072164948453608,0.7905983878449461,0.7497139351177238,0.7376132674238357,0.7302166817980204,0.7290230478457655,0.7289203257091452,0.7203498126310723,0.7116940984006456,0.7099121851244794,0.7045276748456448,0.699419670650905,0.668427708236902,0.6592162404869385,0.6366229366960462,0.62651381925772,0.6224174570808164,0.6165824991949805,0.6072525828041119,0.5976665639728599,0.5869712947662259,0.5310090551211241,0.518804338474145,0.5156041102748504,0.5094726449332198,0.49633958300851055,0.4849909122784545,0.425964664477687,0.42085585399130254,0.41580185246454615,0.35804749012040615,0.3564481351981352,0.35454094516594514,0.2937938241639698,0.29277787049399195,0.28841601644347187,0.21945753121166253,0.2167492734699886,0.14620814479638009,0.07377777777777778,0.07264957264957264,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],\"type\":\"scatter\"}],                        {\"template\":{\"data\":{\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"rgb(237,237,237)\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"bar\":[{\"error_x\":{\"color\":\"rgb(51,51,51)\"},\"error_y\":{\"color\":\"rgb(51,51,51)\"},\"marker\":{\"line\":{\"color\":\"rgb(237,237,237)\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"rgb(51,51,51)\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"rgb(51,51,51)\"},\"baxis\":{\"endlinecolor\":\"rgb(51,51,51)\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"rgb(51,51,51)\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":0,\"tickcolor\":\"rgb(237,237,237)\",\"ticklen\":6,\"ticks\":\"inside\"},\"type\":\"choropleth\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":0,\"tickcolor\":\"rgb(237,237,237)\",\"ticklen\":6,\"ticks\":\"inside\"},\"type\":\"contourcarpet\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":0,\"tickcolor\":\"rgb(237,237,237)\",\"ticklen\":6,\"ticks\":\"inside\"},\"colorscale\":[[0,\"rgb(20,44,66)\"],[1,\"rgb(90,179,244)\"]],\"type\":\"contour\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":0,\"tickcolor\":\"rgb(237,237,237)\",\"ticklen\":6,\"ticks\":\"inside\"},\"colorscale\":[[0,\"rgb(20,44,66)\"],[1,\"rgb(90,179,244)\"]],\"type\":\"heatmapgl\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":0,\"tickcolor\":\"rgb(237,237,237)\",\"ticklen\":6,\"ticks\":\"inside\"},\"colorscale\":[[0,\"rgb(20,44,66)\"],[1,\"rgb(90,179,244)\"]],\"type\":\"heatmap\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":0,\"tickcolor\":\"rgb(237,237,237)\",\"ticklen\":6,\"ticks\":\"inside\"},\"colorscale\":[[0,\"rgb(20,44,66)\"],[1,\"rgb(90,179,244)\"]],\"type\":\"histogram2dcontour\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":0,\"tickcolor\":\"rgb(237,237,237)\",\"ticklen\":6,\"ticks\":\"inside\"},\"colorscale\":[[0,\"rgb(20,44,66)\"],[1,\"rgb(90,179,244)\"]],\"type\":\"histogram2d\"}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":0,\"tickcolor\":\"rgb(237,237,237)\",\"ticklen\":6,\"ticks\":\"inside\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"tickcolor\":\"rgb(237,237,237)\",\"ticklen\":6,\"ticks\":\"inside\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"tickcolor\":\"rgb(237,237,237)\",\"ticklen\":6,\"ticks\":\"inside\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"tickcolor\":\"rgb(237,237,237)\",\"ticklen\":6,\"ticks\":\"inside\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"tickcolor\":\"rgb(237,237,237)\",\"ticklen\":6,\"ticks\":\"inside\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"tickcolor\":\"rgb(237,237,237)\",\"ticklen\":6,\"ticks\":\"inside\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"tickcolor\":\"rgb(237,237,237)\",\"ticklen\":6,\"ticks\":\"inside\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"tickcolor\":\"rgb(237,237,237)\",\"ticklen\":6,\"ticks\":\"inside\"}},\"type\":\"scattermapbox\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"tickcolor\":\"rgb(237,237,237)\",\"ticklen\":6,\"ticks\":\"inside\"}},\"type\":\"scatterpolargl\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"tickcolor\":\"rgb(237,237,237)\",\"ticklen\":6,\"ticks\":\"inside\"}},\"type\":\"scatterpolar\"}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"tickcolor\":\"rgb(237,237,237)\",\"ticklen\":6,\"ticks\":\"inside\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":0,\"tickcolor\":\"rgb(237,237,237)\",\"ticklen\":6,\"ticks\":\"inside\"},\"colorscale\":[[0,\"rgb(20,44,66)\"],[1,\"rgb(90,179,244)\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"rgb(237,237,237)\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"rgb(217,217,217)\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"tickcolor\":\"rgb(237,237,237)\",\"ticklen\":6,\"ticks\":\"inside\"}},\"colorscale\":{\"sequential\":[[0,\"rgb(20,44,66)\"],[1,\"rgb(90,179,244)\"]],\"sequentialminus\":[[0,\"rgb(20,44,66)\"],[1,\"rgb(90,179,244)\"]]},\"colorway\":[\"#F8766D\",\"#A3A500\",\"#00BF7D\",\"#00B0F6\",\"#E76BF3\"],\"font\":{\"color\":\"rgb(51,51,51)\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"rgb(237,237,237)\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"white\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"rgb(237,237,237)\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showgrid\":true,\"tickcolor\":\"rgb(51,51,51)\",\"ticks\":\"outside\"},\"bgcolor\":\"rgb(237,237,237)\",\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showgrid\":true,\"tickcolor\":\"rgb(51,51,51)\",\"ticks\":\"outside\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"rgb(237,237,237)\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"showgrid\":true,\"tickcolor\":\"rgb(51,51,51)\",\"ticks\":\"outside\",\"zerolinecolor\":\"white\"},\"yaxis\":{\"backgroundcolor\":\"rgb(237,237,237)\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"showgrid\":true,\"tickcolor\":\"rgb(51,51,51)\",\"ticks\":\"outside\",\"zerolinecolor\":\"white\"},\"zaxis\":{\"backgroundcolor\":\"rgb(237,237,237)\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"showgrid\":true,\"tickcolor\":\"rgb(51,51,51)\",\"ticks\":\"outside\",\"zerolinecolor\":\"white\"}},\"shapedefaults\":{\"fillcolor\":\"black\",\"line\":{\"width\":0},\"opacity\":0.3},\"ternary\":{\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showgrid\":true,\"tickcolor\":\"rgb(51,51,51)\",\"ticks\":\"outside\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showgrid\":true,\"tickcolor\":\"rgb(51,51,51)\",\"ticks\":\"outside\"},\"bgcolor\":\"rgb(237,237,237)\",\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showgrid\":true,\"tickcolor\":\"rgb(51,51,51)\",\"ticks\":\"outside\"}},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showgrid\":true,\"tickcolor\":\"rgb(51,51,51)\",\"ticks\":\"outside\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\"},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showgrid\":true,\"tickcolor\":\"rgb(51,51,51)\",\"ticks\":\"outside\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\"}}},\"shapes\":[{\"line\":{\"dash\":\"dash\"},\"type\":\"line\",\"x0\":0,\"x1\":1,\"y0\":1,\"y1\":0}],\"xaxis\":{\"range\":[0,1],\"constrain\":\"domain\",\"title\":{\"text\":\"Recall\"}},\"yaxis\":{\"range\":[0,1],\"constrain\":\"domain\",\"scaleanchor\":\"x\",\"scaleratio\":1,\"title\":{\"text\":\"Precision\"}},\"title\":{},\"margin\":{\"r\":0,\"t\":30,\"l\":0,\"b\":0}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('3ee19aa1-f675-4ce8-9a99-619a763a134d');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "plot = results.plot_pr_curves(classes=['car','motorcycle','truck'])\n",
        "plot.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The high confidence filtering threshold and the IoU sweep values hold a huge impact on the evaluation metrics. \n",
        "E.g:\n",
        "\n",
        "confidence threshold = 0.85 > mAP = 0.27\\\n",
        "confidence threshold = 0.75 > mAP = 0.30 \\\n",
        "confidence threshold = 0.6 > mAP = 0.33 \\\n"
      ],
      "metadata": {
        "id": "z3sGNdqZTYiP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "How can improve our results?\n",
        "\n",
        "\n",
        "\n",
        "*   **Model Fine-Tuning**: Re-initializing the last layers (FastRCNNPredictor) and re-train for a few epochs (This involves hyperparameter tuning, learning rate scheduling, regularization techniquesâ€¦).\n",
        "*   **Data Augmentation**: Techniques such as random crops, rotations, scaling, and flipping can help the model generalize better and handle different variations and orientations of the objects.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "yeZXwAVHmuBg"
      }
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "PTQfyCiOzEuw",
        "z6Ktsx9ehp-E",
        "KZril-Xtp-g0"
      ],
      "authorship_tag": "ABX9TyO/VNlRb/24CsDBzYZDljrO",
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}